{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load the tips dataset\n",
    "tips_df = sns.load_dataset('tips')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(tips_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = ['sex', 'smoker', 'day','time']\n",
    "numerical_cols = ['size', 'total_bill', 'tip']\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(tips_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill       tip     sex smoker  day    time      size\n",
      "0   -0.314711 -1.439947  Female     No  Sun  Dinner -0.600193\n",
      "1   -1.063235 -0.969205    Male     No  Sun  Dinner  0.453383\n",
      "2    0.137780  0.363356    Male     No  Sun  Dinner  0.453383\n",
      "3    0.438315  0.225754    Male     No  Sun  Dinner -0.600193\n",
      "4    0.540745  0.443020  Female     No  Sun  Dinner  1.506958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have the 'tips_df' DataFrame and 'numerical_cols' variable from the previous code\n",
    "\n",
    "# Create a pipeline for numerical columns\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Replace missing values with mean\n",
    "    ('scaler', StandardScaler())  # Standard scaling\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the numerical columns\n",
    "tips_df[numerical_cols] = numerical_pipeline.fit_transform(tips_df[numerical_cols])\n",
    "\n",
    "# Display the first few rows of the preprocessed DataFrame\n",
    "print(tips_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       size  total_bill       tip  sex_Female  sex_Male  smoker_No  \\\n",
      "0 -0.600193   -0.314711 -1.439947         1.0       0.0        1.0   \n",
      "1  0.453383   -1.063235 -0.969205         0.0       1.0        1.0   \n",
      "2  0.453383    0.137780  0.363356         0.0       1.0        1.0   \n",
      "3 -0.600193    0.438315  0.225754         0.0       1.0        1.0   \n",
      "4  1.506958    0.540745  0.443020         1.0       0.0        1.0   \n",
      "\n",
      "   smoker_Yes  day_Fri  day_Sat  day_Sun  day_Thur  \n",
      "0         0.0      0.0      0.0      1.0       0.0  \n",
      "1         0.0      0.0      0.0      1.0       0.0  \n",
      "2         0.0      0.0      0.0      1.0       0.0  \n",
      "3         0.0      0.0      0.0      1.0       0.0  \n",
      "4         0.0      0.0      0.0      1.0       0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Assuming you have the 'tips_df' DataFrame, 'categorical_cols', and 'numerical_cols' variables from the previous code\n",
    "\n",
    "# Create a numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Replace missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Standard scaling\n",
    "])\n",
    "\n",
    "# Create a categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Replace missing values with the most frequent value\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding\n",
    "])\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_cols),\n",
    "        ('cat', categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply the column transformer to the entire DataFrame\n",
    "tips_df_transformed = preprocessor.fit_transform(tips_df)\n",
    "\n",
    "# Convert the transformed array back to a DataFrame for display\n",
    "columns = numerical_cols + preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols).tolist()\n",
    "tips_df_transformed = pd.DataFrame(tips_df_transformed, columns=columns)\n",
    "\n",
    "# Display the first few rows of the preprocessed DataFrame\n",
    "print(tips_df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X = tips_df_transformed\n",
    "y = tips_df['time']\n",
    "\n",
    "# Split the dataset into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 150}\n",
      "\n",
      "Performance of the Best Model:\n",
      "Accuracy: 0.9730\n",
      "Precision: 0.9730\n",
      "Recall: 0.9730\n",
      "F1 Score: 0.9730\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have the 'tips_df_transformed' DataFrame from the previous code\n",
    "X = tips_df_transformed\n",
    "y = tips_df['time']  # This is the target variable you want to predict\n",
    "\n",
    "# Split the dataset into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a new pipeline for the classifier\n",
    "classifier_pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 150],\n",
    "    'classifier__max_depth': [5, 10, 15, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier_pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the performance of the best model on the test set\n",
    "best_predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, best_predictions)\n",
    "precision = precision_score(y_test, best_predictions, average='weighted')\n",
    "recall = recall_score(y_test, best_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, best_predictions, average='weighted')\n",
    "\n",
    "print(\"\\nPerformance of the Best Model:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
