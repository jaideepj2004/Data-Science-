{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is a projection and how is it used in PCA?\n",
    "\n",
    "-> Projection is a technique where we take the projection of one vector onto another vector , this method is used in maximising the cost function as over there we use the projection , projection is calculated by using the formula (a.b)/|b| where b is the vector where we are taking the projection and a is the vector which is projected \n",
    "\n",
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "\n",
    "-> 1. find the correlation matrix \n",
    "2. find the eigen vector and eigen values of that correlation matrix\n",
    "3. arrange all the eigen values in decreasing order \n",
    "4. merge their corresponding vector as per the required number of dimension , there should be n  merged eigen vectors if we want to reduce to n dimension \n",
    "\n",
    "It is trying to achieve the vector on which if we take the projection of all the points than  we should get maximum variance\n",
    "\n",
    "Q3. What is the relationship between covariance matrices and PCA?\n",
    "\n",
    "-> Covariance matrix calculation is the second step in PCA after the standardisation of the points \n",
    "\n",
    "Q4. How does the choice of number of principal components impact the performance of PCA?\n",
    "\n",
    "-> More is the number of principal componenet better is the performance of PCA , as they will capture more variance \n",
    "\n",
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n",
    "\n",
    "-> Instead of completely dropping a feature , we can capture it variance thus PCA can be used in feature selection \n",
    "\n",
    "Q6. What are some common applications of PCA in data science and machine learning?\n",
    "\n",
    "-> To remove the curse of dimensionality and to visualize a higher dimension data in 1d , 2d or 3d \n",
    "\n",
    "Q7.What is the relationship between spread and variance in PCA?\n",
    "\n",
    "-> Spread is proportional to variance captures\n",
    "\n",
    "Q8. How does PCA use the spread and variance of the data to identify principal components?\n",
    "\n",
    "-> Only those principal componenets are selected that have the maximum variance captures , or maximum spread , as spread and variance are proportional \n",
    "\n",
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?\n",
    "\n",
    "-> While going from high dimension to low dimension pca first selects those eigen vector that have the higest eigen values . High eigen values means that they have captured more variance \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
